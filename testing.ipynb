{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FACE RECOGNITION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#violajones face detection using opencv\n",
    "def detect_faces(image_path, scaleFactor, minNeighbors, minSize):\n",
    "    #read image\n",
    "    image = cv2.imread(image_path)\n",
    "    #load the pre-trained model\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    #convert the image to gray scale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray_image,\n",
    "        scaleFactor=scaleFactor,\n",
    "        minNeighbors=minNeighbors,\n",
    "        minSize=minSize,\n",
    "    )\n",
    "    #if no bounding boxes are found, return 0,0,0,0\n",
    "    if len(faces) == 0:\n",
    "\n",
    "        return np.array([0,0,0,0])\n",
    "    #return the bounding boxes\n",
    "    return faces.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(box1, box2):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[0] + box1[2], box2[0] + box2[2])\n",
    "    y2 = min(box1[1] + box1[3], box2[1] + box2[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    #compute the area of both the prediction and ground-truth boxes\n",
    "    box1_area = box1[2] * box1[3]\n",
    "    box2_area = box2[2] * box2[3]\n",
    "\n",
    "    # compute the union area\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    #return IoU\n",
    "    return inter_area / union_area if union_area > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dataset, scaleFactor, minNeighbors, minSize):\n",
    "    #iou scores for each sample\n",
    "    iou_scores = []\n",
    "    for item in dataset[\"identity\"].unique():\n",
    "        #get all the samples for a particular identity\n",
    "        df = dataset[dataset[\"identity\"] == item]\n",
    "        \n",
    "        #for each sample of the same identity\n",
    "        for i in range(len(df)):            \n",
    "            path = \"data/\" + str(df.iloc[i][\"idx\"]) + \".jpg\"\n",
    "             # Ground truth bounding boxes\n",
    "            gt_box = [df.iloc[i][\"x_1\"], df.iloc[i][\"y_1\"], df.iloc[i][\"width\"], df.iloc[i][\"height\"]] \n",
    "            \n",
    "            # Detected bounding boxes with viola-jones\n",
    "            detected_face = detect_faces(path, scaleFactor, minNeighbors, minSize)\n",
    "            \n",
    "            #compute iou\n",
    "            iou = compute_iou(gt_box, detected_face)\n",
    "            \n",
    "                \n",
    "        iou_scores.append(iou)\n",
    "\n",
    "    avg_iou = np.mean(iou_scores) if iou_scores else 0\n",
    "    return avg_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_parameters(dataset):\n",
    "    best_params = {}\n",
    "    best_iou = 0\n",
    "    #grid search for best parameters\n",
    "    for scaleFactor in [1.1,1.2,1.3 ,1.4]:\n",
    "        for minNeighbors in range(3, 6):\n",
    "            for minSize in [(20, 20), (30, 30)]:\n",
    "                avg_iou = evaluate_model(dataset, scaleFactor, minNeighbors, minSize)\n",
    "                if avg_iou > best_iou:\n",
    "                    best_iou = avg_iou\n",
    "                    #dict of best parameters\n",
    "                    best_params = {\n",
    "                        \"scaleFactor\": scaleFactor,\n",
    "                        \"minNeighbors\": minNeighbors,\n",
    "                        \"minSize\": minSize,\n",
    "                    }\n",
    "    return best_params, best_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataset, best_params):\n",
    "    #test the model with the optimized parameters, calc avg iou\n",
    "    avg_iou = evaluate_model(\n",
    "        dataset,\n",
    "        best_params[\"scaleFactor\"],\n",
    "        best_params[\"minNeighbors\"],\n",
    "        best_params[\"minSize\"],\n",
    "    )\n",
    "    print(f\"Average IoU on test set: {avg_iou}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('CelebA-HQ-small.csv')\n",
    "# Get the train split\n",
    "df_test = df.loc[df[\"split\"] == \"train\"]\n",
    "# train the model\n",
    "best_params, best_iou =  optimize_parameters(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'scaleFactor': 1.2, 'minNeighbors': 3, 'minSize': (20, 20)}, Best IoU: 0.6754693822947886\n",
      "Average IoU on test set: 0.5900289445468367\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Best parameters: {best_params}, Best IoU: {best_iou}\")\n",
    "# Get the test split\n",
    "df_test = df.loc[df[\"split\"] == \"test\"]\n",
    "# test the model\n",
    "test_model(best_params=best_params, dataset=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_feature_vectors(dataset,function, n_points=8, radius=1, grid_size=(4,4), method=\"uniform\", scaleFactor = 1.3, minNeighbors=3, minSize=(20,20), useBoundingBox=True):\n",
    "    feature_vectors = []\n",
    "    image_ids = []\n",
    "    for i in range(len(dataset)):   \n",
    "        path = \"data/\" + str(df.iloc[i][\"idx\"]) + \".jpg\"\n",
    "        # Detected bounding boxes with viola-jones\n",
    "        detected_face = detect_faces(path, scaleFactor, minNeighbors, minSize)\n",
    "        image_ids.append(df.iloc[i][\"idx\"])\n",
    "        if function == \"lbp\":\n",
    "            feature_vectors.append(extract_features_lbp(path, detected_face, n_points, radius, grid_size, method, useBoundingBox=useBoundingBox))\n",
    "        elif function == \"hog\":\n",
    "            feature_vectors.append(extract_features_hog(path, detected_face, useBoundingBox=useBoundingBox))\n",
    "    return feature_vectors, image_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_distance(A, B):\n",
    " \n",
    "    chi = 0.5 * np.sum([((a - b) ** 2) / (a + b + 1e-8) \n",
    "                      for (a, b) in zip(A, B)])\n",
    "    return chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genuines_impostors_scores(dataset,function,n_points=8, radius=1, grid_size=(4,4), method=\"uniform\", scaleFactor = 1.3, minNeighbors=3, minSize=(20,20),useBoundingBox=True):\n",
    "    #extract feature vectors for all the samples\n",
    "    genuines = []\n",
    "    impostors = []\n",
    "    feature_vectors,image_ids = extract_all_feature_vectors(dataset,function,n_points=n_points, radius=radius, grid_size=grid_size, method=method, scaleFactor = scaleFactor, minNeighbors=minNeighbors, minSize=minSize,useBoundingBox=useBoundingBox)\n",
    "    for feature_vector, image_id in zip(feature_vectors, image_ids):\n",
    "        #get the identity of the sample\n",
    "        identity = dataset[dataset[\"idx\"] == image_id][\"identity\"].values[0]\n",
    "        #get all the samples of the same identity\n",
    "        df_gen = dataset[dataset[\"identity\"] == identity]\n",
    "        #get all the samples of different identity\n",
    "        df_imp = dataset[dataset[\"identity\"] != identity]\n",
    "        for i in range(len(df_gen)):\n",
    "            #compute the chi2 distance between the feature vectors\n",
    "            genuines.append(chi2_distance(feature_vector, feature_vectors[i]))\n",
    "            \n",
    "        for i in range(len(df_imp)):\n",
    "            #compute the chi2 distance between the feature vectors\n",
    "            impostors.append(chi2_distance(feature_vector, feature_vectors[i]))\n",
    "    return genuines, impostors\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(genuines, impostors, start_treshold, end_treshold, step):\n",
    "    classification_acc = []\n",
    "    prec = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "\n",
    "    for treshold in range(start_treshold, end_treshold, step):\n",
    "        correctly_classified_gen = 0\n",
    "        correctly_classified_imp = 0\n",
    "        #count number of correctly classified genuines\n",
    "        for el in genuines:\n",
    "            if el <= treshold:\n",
    "                correctly_classified_gen+=1\n",
    "        #count number of correctly classified impostors\n",
    "        for el in impostors:\n",
    "            if el > treshold:\n",
    "                correctly_classified_imp+=1\n",
    "        \n",
    "        classification_acc.append((correctly_classified_gen + correctly_classified_imp)/(len(genuines) + len(impostors)))\n",
    "        prec.append((correctly_classified_gen)/(correctly_classified_gen + len(impostors) - correctly_classified_imp))\n",
    "        recall.append(correctly_classified_gen/len(genuines))\n",
    "        f1.append((2*prec[-1]*recall[-1])/(prec[-1] + recall[-1] + 0.00000001))\n",
    "    \n",
    "    \n",
    "    indeks = f1.index(max(f1))\n",
    "    best_treshold = start_treshold + indeks*step\n",
    "\n",
    "    return best_treshold, classification_acc[indeks], prec[indeks], recall[indeks], f1[indeks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(genuine, impostors):\n",
    "    genuine_frequency= []\n",
    "    genuine_count = []\n",
    "\n",
    "\n",
    "    impostors_frequency= []\n",
    "    impostors_count = []\n",
    "\n",
    "    #create frequency and count\n",
    "    for i in range(0, int(max(genuine))+1):\n",
    "        genuine_frequency.append(genuine.count(i))\n",
    "        genuine_count.append(i)\n",
    "\n",
    "        #same for impostors\n",
    "    for i in range(0, int(max(impostors))+1):\n",
    "        impostors_frequency.append(impostors.count(i))\n",
    "        impostors_count.append(i)\n",
    "\n",
    "    plt.plot(genuine_count, genuine_frequency,label=\"genuines\")\n",
    "    plt.plot(impostors_count, impostors_frequency, label=\"impostors\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_lbp(image_path, bounding_box, n_points=8, radius=1 ,grid_size=(8,8), useBoundingBox=True):\n",
    "    #read image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    face_region = image[bounding_box[1] : bounding_box[1] + bounding_box[3],\n",
    "        bounding_box[0] : bounding_box[0] + bounding_box[2]]\n",
    "    \n",
    "    if bounding_box.all() and useBoundingBox:\n",
    "        lbp = local_binary_pattern(face_region, n_points, radius, method=\"uniform\")\n",
    "    else:\n",
    "        lbp = local_binary_pattern(image, n_points, radius, method=\"uniform\")   \n",
    "\n",
    "    lbp = cv2.resize(lbp, (256, 256))   \n",
    "\n",
    "    features = []\n",
    "    bins = n_points + 2\n",
    "\n",
    "    height, width = lbp.shape\n",
    "\n",
    "    for wx in range(0,width,grid_size[0]):\n",
    "        for wy in range(0,height,grid_size[1]):\n",
    "            hist = np.zeros(bins)\n",
    "            for x in range(wx, min(wx + grid_size[0], width)):\n",
    "                for y in range(wy, min(wy + grid_size[1], height)):\n",
    "                    hist[int(lbp[y, x])] += 1\n",
    "            features.extend(hist)\n",
    "\n",
    "    return np.array(features), lbp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/123.jpg\"\n",
    "face_box  = detect_faces(image_path, 1.3, 3, (20,20))\n",
    "\n",
    "feature1,lbp = extract_features_lbp(image_path, face_box, n_points=24, radius=3, grid_size=(4,4))\n",
    "#cv2.imshow(\"lbp\",lbp)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/285.jpg\"\n",
    "face_box  = detect_faces(image_path, 1.3, 3, (20,20))\n",
    "\n",
    "feature2,lbp = extract_features_lbp(image_path, face_box, n_points=24, radius=3, grid_size=(4,4), useBoundingBox=True)\n",
    "#cv2.imshow(\"lbp\",lbp)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106496 106496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(32166.05206428853)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(feature1), len(feature2))\n",
    "chi2_distance(feature1, feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_features_lbp() got multiple values for argument 'useBoundingBox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCelebA-HQ-small.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[::\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m lbp_genuines,lbp_impostors \u001b[38;5;241m=\u001b[39m \u001b[43mget_genuines_impostors_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlbp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m, in \u001b[0;36mget_genuines_impostors_scores\u001b[1;34m(dataset, function, n_points, radius, grid_size, method, scaleFactor, minNeighbors, minSize, useBoundingBox)\u001b[0m\n\u001b[0;32m      3\u001b[0m genuines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m impostors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 5\u001b[0m feature_vectors,image_ids \u001b[38;5;241m=\u001b[39m \u001b[43mextract_all_feature_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaleFactor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaleFactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminNeighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminNeighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminSize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminSize\u001b[49m\u001b[43m,\u001b[49m\u001b[43museBoundingBox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43museBoundingBox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature_vector, image_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(feature_vectors, image_ids):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#get the identity of the sample\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     identity \u001b[38;5;241m=\u001b[39m dataset[dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m image_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m, in \u001b[0;36mextract_all_feature_vectors\u001b[1;34m(dataset, function, n_points, radius, grid_size, method, scaleFactor, minNeighbors, minSize, useBoundingBox)\u001b[0m\n\u001b[0;32m      8\u001b[0m image_ids\u001b[38;5;241m.\u001b[39mappend(df\u001b[38;5;241m.\u001b[39miloc[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m function \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 10\u001b[0m     feature_vectors\u001b[38;5;241m.\u001b[39mappend(\u001b[43mextract_features_lbp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetected_face\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43museBoundingBox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43museBoundingBox\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m function \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhog\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     12\u001b[0m     feature_vectors\u001b[38;5;241m.\u001b[39mappend(extract_features_hog(path, detected_face, useBoundingBox\u001b[38;5;241m=\u001b[39museBoundingBox))\n",
      "\u001b[1;31mTypeError\u001b[0m: extract_features_lbp() got multiple values for argument 'useBoundingBox'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CelebA-HQ-small.csv')\n",
    "df = df.iloc[::10]\n",
    "lbp_genuines,lbp_impostors = get_genuines_impostors_scores(df, \"lbp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "dataset = pd.read_csv('CelebA-HQ-small.csv')\n",
    "lbp_genuines,lbp_impostors = get_genuines_impostors_scores(dataset, \"lbp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of oriented gradients - HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_hog(image_path, bounding_box,orientatins=9, piexels_per_cell = (8,8), cells_per_block = (2,2), image_size=(256,256), useBoundingBox=True):\n",
    "    image = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    \n",
    "    face_region = image[bounding_box[1] : bounding_box[1] + bounding_box[3],\n",
    "        bounding_box[0] : bounding_box[0] + bounding_box[2]]\n",
    "    \n",
    "    \n",
    "    if bounding_box.all() and useBoundingBox:\n",
    "        #face_region = cv2.resize(face_region, image_size)\n",
    "        features,im = hog(face_region, orientations=orientatins, pixels_per_cell=piexels_per_cell, cells_per_block=cells_per_block, visualize=True)\n",
    "    else:\n",
    "        #image = cv2.resize(image, image_size)\n",
    "        features,im = hog(image, orientations=orientatins, pixels_per_cell=piexels_per_cell, cells_per_block=cells_per_block, visualize=True)\n",
    "\n",
    "\n",
    "    return features,im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/123.jpg\"\n",
    "face_box  = detect_faces(image_path, 1.3, 3, (20,20))\n",
    "\n",
    "feature1,im = extract_features_hog(image_path, face_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/285.jpg\"\n",
    "face_box  = detect_faces(image_path, 1.3, 3, (20,20))\n",
    "\n",
    "feature2,im = extract_features_hog(image_path, face_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"hog\",im)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4129.662701870718)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_distance(feature1, feature2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_genuines, hog_impostors = get_genuines_impostors_scores(dataset, \"hog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.10225245618656 242.87136455831742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(1.5045868453550197), np.float64(1.1848743694056472))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(hog_genuines), np.mean(hog_impostors))\n",
    "np.mean(lbp_genuines), np.mean(lbp_impostors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DENSE SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/112.jpg\"\n",
    "# Load and preprocess the image\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "boxes = detect_faces(image_path, 1.3, 3, (20, 20))\n",
    "\n",
    "image = image[boxes[1] : boxes[1] + boxes[3], boxes[0] : boxes[0] + boxes[2]]\n",
    "# Parameters for Dense SIFT\n",
    "grid_spacing = 8  # Distance between grid points\n",
    "patch_size = 16   # Size of the patch for each descriptor\n",
    "\n",
    "# Initialize SIFT\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Generate grid points\n",
    "keypoints = []\n",
    "h, w = image.shape\n",
    "for y in range(0, h, grid_spacing):\n",
    "    for x in range(0, w, grid_spacing):\n",
    "        keypoints.append(cv2.KeyPoint(x, y, patch_size))\n",
    "\n",
    "# Compute Dense SIFT descriptors\n",
    "keypoints, descriptors = sift.compute(image, keypoints)\n",
    "\n",
    "# Visualize grid points\n",
    "image_with_keypoints = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.imshow(image_with_keypoints, cmap=\"gray\")\n",
    "plt.title(\"Dense SIFT Keypoints\")\n",
    "plt.show()\n",
    "\n",
    "# Print descriptor shape\n",
    "print(f\"Number of descriptors: {len(descriptors)}\")\n",
    "print(f\"Descriptor size: {descriptors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOG feature vector size: (298116,)\n"
     ]
    }
   ],
   "source": [
    "image_path = \"data/112.jpg\"\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "face_box = detect_faces(image_path, 1.2, 3, (20, 20))\n",
    "face = image[face_box[1]:face_box[1] + face_box[3], face_box[0]:face_box[0] + face_box[2]]\n",
    "\n",
    "#fixed_face = cv2.resize(face, (64, 64))\n",
    "# Parameters for HOG\n",
    "pixels_per_cell = (8, 8)\n",
    "cells_per_block = (2, 2) \n",
    "orientations = 9 #bin size for the histogram\n",
    "\n",
    "# Compute HOG features and HOG image\n",
    "hog_features = hog(\n",
    "    face,\n",
    "    orientations=orientations,\n",
    "    pixels_per_cell=pixels_per_cell,\n",
    "    cells_per_block=cells_per_block,\n",
    "\n",
    ")\n",
    "\n",
    "# Display the HOG image\n",
    "#plt.figure(figsize=(8, 8))\n",
    "#plt.axis(\"off\")\n",
    "#plt.title(\"HOG Visualization\")\n",
    "#plt.imshow(hog_image, cmap=\"gray\")\n",
    "#plt.show()\n",
    "\n",
    "# HOG features vector\n",
    "print(f\"HOG feature vector size: {hog_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 92\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "7 5\n",
      "7 6\n",
      "7 7\n",
      "(704,)\n",
      "[np.float64(0.055056710774982205), np.float64(0.07951323251408374), np.float64(0.06758034026457044), np.float64(0.12051039697528294), np.float64(0.21620982986741938), np.float64(0.11862003780704321), np.float64(0.06982514177685512), np.float64(0.08187618147438341), np.float64(0.07455103969745444), np.float64(0.11625708884674354), np.float64(0.0), np.float64(0.03414461247633017), np.float64(0.06769848771258542), np.float64(0.0621455576558812), np.float64(0.12653591682404708), np.float64(0.2655954631376824), np.float64(0.14756616257071412), np.float64(0.08034026465018862), np.float64(0.06876181474472026), np.float64(0.0600189035916115), np.float64(0.08719281663505765), np.float64(0.0), np.float64(0.03438090737236013), np.float64(0.06403591682412094), np.float64(0.05671077504719197), np.float64(0.13267958412082623), np.float64(0.2556710775044238), np.float64(0.15359168241947826), np.float64(0.08861058601123746), np.float64(0.06592627599236067), np.float64(0.06320888468801605), np.float64(0.08518431001880294), np.float64(0.0), np.float64(0.0317816635160305), np.float64(0.06805293005663036), np.float64(0.06249999999992615), np.float64(0.14177693761797994), np.float64(0.19801512287311196), np.float64(0.16257088846861698), np.float64(0.09699905482030127), np.float64(0.06663516068045057), np.float64(0.0685255198486903), np.float64(0.1031427221170804), np.float64(0.0), np.float64(0.03284499054816535), np.float64(0.07100661625700495), np.float64(0.05612003780711706), np.float64(0.14319470699415973), np.float64(0.1680056710773062), np.float64(0.16198015122854206), np.float64(0.10964083175790448), np.float64(0.07998582230614368), np.float64(0.07041587901693003), np.float64(0.10680529300554488), np.float64(0.0), np.float64(0.03556238185250996), np.float64(0.07608695652164923), np.float64(0.061082230623746354), np.float64(0.14024102079378514), np.float64(0.1498109640829988), np.float64(0.15867202268412253), np.float64(0.11200378071820415), np.float64(0.07325141776928963), np.float64(0.0784499054819489), np.float64(0.11483931947056374), np.float64(0.0), np.float64(0.0374527410207497), np.float64(0.0784499054819489), np.float64(0.06297258979198608), np.float64(0.1335066162569311), np.float64(0.20073251417745658), np.float64(0.1512287334591786), np.float64(0.09168241965962702), np.float64(0.07596880907363425), np.float64(0.06439035916816588), np.float64(0.10361531190914033), np.float64(0.0), np.float64(0.036980151228689764), np.float64(0.08849243856322248), np.float64(0.05068525519842782), np.float64(0.12039224952726796), np.float64(0.21975425330786888), np.float64(0.1434310018901897), np.float64(0.08435727788269806), np.float64(0.07998582230614368), np.float64(0.07738657844981404), np.float64(0.09853497164449605), np.float64(0.0), np.float64(0.04867674858217311), np.float64(0.09711720226831626), np.float64(0.06025519848764147), np.float64(0.11094045368606929), np.float64(0.23416824196569686), np.float64(0.11283081285430903), np.float64(0.06698960302449551), np.float64(0.0912098298675671), np.float64(0.06876181474472026), np.float64(0.10905009451782956), np.float64(0.0), np.float64(0.033081285444195314), np.float64(0.07715028355378407), np.float64(0.05434782608689231), np.float64(0.12381852551970247), np.float64(0.2713846880904166), np.float64(0.15099243856314862), np.float64(0.07372400756134956), np.float64(0.07821361058591893), np.float64(0.05434782608689231), np.float64(0.08293950850651825), np.float64(0.0), np.float64(0.029300567107715853), np.float64(0.060137051039626487), np.float64(0.05990075614359652), np.float64(0.14496691871438447), np.float64(0.25519848771236386), np.float64(0.1723771266538606), np.float64(0.08329395085056321), np.float64(0.06025519848764147), np.float64(0.053166351606742476), np.float64(0.08140359168232347), np.float64(0.0), np.float64(0.03615311909258488), np.float64(0.06533553875228575), np.float64(0.06793478260861538), np.float64(0.14390359168224962), np.float64(0.21219281663490996), np.float64(0.1513468809071936), np.float64(0.08979206049138728), np.float64(0.07147920604906488), np.float64(0.06557183364831572), np.float64(0.09629017013221138), np.float64(0.0), np.float64(0.0388705103969295), np.float64(0.07289697542524468), np.float64(0.060137051039626487), np.float64(0.1447306238183545), np.float64(0.17060491493363586), np.float64(0.16008979206030233), np.float64(0.1038516068051703), np.float64(0.07183364839310984), np.float64(0.0741965973534095), np.float64(0.10278827977303545), np.float64(0.0), np.float64(0.03686200378067478), np.float64(0.07266068052921472), np.float64(0.055411153119027154), np.float64(0.14083175803386005), np.float64(0.15099243856314862), np.float64(0.15961720226824241), np.float64(0.11200378071820415), np.float64(0.07904064272202381), np.float64(0.08010396975415866), np.float64(0.11247637051026407), np.float64(0.0), np.float64(0.03863421550089953), np.float64(0.08258506616247331), np.float64(0.05647448015116201), np.float64(0.12700850661610702), np.float64(0.18879962192794328), np.float64(0.14945652173895385), np.float64(0.1038516068051703), np.float64(0.07206994328913979), np.float64(0.07313327032127465), np.float64(0.10798676748569472), np.float64(0.0), np.float64(0.038161625708839596), np.float64(0.06628071833640561), np.float64(0.05269376181468254), np.float64(0.13019848771251158), np.float64(0.26583175803371234), np.float64(0.14792060491475906), np.float64(0.08069470699423358), np.float64(0.06179111531183625), np.float64(0.06096408317573137), np.float64(0.09546313799610648), np.float64(0.0), np.float64(0.053520793950787425), np.float64(0.09109168241955211), np.float64(0.058719281663446685), np.float64(0.10964083175790448), np.float64(0.22058128544397376), np.float64(0.1102315689979794), np.float64(0.07289697542524468), np.float64(0.08920132325131237), np.float64(0.07372400756134956), np.float64(0.12039224952726796), np.float64(0.0), np.float64(0.037570888468764684), np.float64(0.07466918714546943), np.float64(0.0600189035916115), np.float64(0.14035916824180014), np.float64(0.2160916824194044), np.float64(0.1532372400754333), np.float64(0.08211247637041337), np.float64(0.07868620037797885), np.float64(0.06131852551977632), np.float64(0.09593572778816642), np.float64(0.0), np.float64(0.03402646502831518), np.float64(0.059310018903521604), np.float64(0.05706521739123692), np.float64(0.14378544423423464), np.float64(0.25059073723977954), np.float64(0.16729678638921633), np.float64(0.07608695652164923), np.float64(0.06391776937610595), np.float64(0.05623818525513204), np.float64(0.09168241965962702), np.float64(0.0), np.float64(0.03379017013228522), np.float64(0.05588374291108709), np.float64(0.06474480151221083), np.float64(0.15276465028337338), np.float64(0.21443761814719464), np.float64(0.17509451795820521), np.float64(0.09711720226831626), np.float64(0.06344517958404602), np.float64(0.05765595463131184), np.float64(0.08506616257078796), np.float64(0.0), np.float64(0.033317580340225285), np.float64(0.0621455576558812), np.float64(0.05978260869558154), np.float64(0.1574905482039727), np.float64(0.20025992438539664), np.float64(0.16493383742891665), np.float64(0.09617202268419639), np.float64(0.06970699432884013), np.float64(0.0628544423439711), np.float64(0.09333648393183679), np.float64(0.0), np.float64(0.0289461247636709), np.float64(0.05812854442337177), np.float64(0.05765595463131184), np.float64(0.148393194706819), np.float64(0.26571361058569737), np.float64(0.1723771266538606), np.float64(0.08329395085056321), np.float64(0.061082230623746354), np.float64(0.05092155009445779), np.float64(0.0734877126653196), np.float64(0.0), np.float64(0.03260869565213538), np.float64(0.06817107750464535), np.float64(0.06687145557648053), np.float64(0.14591209829850435), np.float64(0.2020321361056214), np.float64(0.15571833648374794), np.float64(0.09782608695640616), np.float64(0.0692344045367802), np.float64(0.06663516068045057), np.float64(0.09499054820404655), np.float64(0.0), np.float64(0.054702268430937256), np.float64(0.07006143667288509), np.float64(0.051512287334532704), np.float64(0.11625708884674354), np.float64(0.2680765595459971), np.float64(0.1222826086955077), np.float64(0.06675330812846555), np.float64(0.07124291115303491), np.float64(0.06817107750464535), np.float64(0.11094045368606929), np.float64(0.0), np.float64(0.04442344045363371), np.float64(0.08565689981086287), np.float64(0.06060964083168642), np.float64(0.1193289224951331), np.float64(0.2099480151226253), np.float64(0.13267958412082623), np.float64(0.0925094517957319), np.float64(0.08069470699423358), np.float64(0.06864366729670528), np.float64(0.10550567107738007), np.float64(0.0), np.float64(0.036389413988614845), np.float64(0.05942816635153659), np.float64(0.07112476370501992), np.float64(0.15666351606786783), np.float64(0.20793950850637055), np.float64(0.15583648393176294), np.float64(0.08778355387513258), np.float64(0.06793478260861538), np.float64(0.06238185255191117), np.float64(0.09451795841198662), np.float64(0.0), np.float64(0.029300567107715853), np.float64(0.05044896030239786), np.float64(0.05848298676741672), np.float64(0.1560727788277929), np.float64(0.2791824196594055), np.float64(0.16635160680509645), np.float64(0.08104914933827853), np.float64(0.05942816635153659), np.float64(0.04678638941393338), np.float64(0.07289697542524468), np.float64(0.0), np.float64(0.029182419659700868), np.float64(0.05281190926269752), np.float64(0.0614366729677913), np.float64(0.1573724007559577), np.float64(0.2176275992435992), np.float64(0.17178638941378568), np.float64(0.0981805293004511), np.float64(0.06486294896022582), np.float64(0.06179111531183625), np.float64(0.08494801512277297), np.float64(0.0), np.float64(0.03130907372397057), np.float64(0.051157844990487755), np.float64(0.06273629489595611), np.float64(0.1610349716444222), np.float64(0.22778827977288776), np.float64(0.16280718336464695), np.float64(0.09664461247625632), np.float64(0.06722589792052548), np.float64(0.05482041587895224), np.float64(0.08447542533071305), np.float64(0.0), np.float64(0.03213610586007545), np.float64(0.05694706994322194), np.float64(0.05552930056704214), np.float64(0.15205576559528347), np.float64(0.2652410207936374), np.float64(0.16257088846861698), np.float64(0.07632325141767919), np.float64(0.0656899810963307), np.float64(0.05186672967857766), np.float64(0.08163988657835344), np.float64(0.0), np.float64(0.030245746691835718), np.float64(0.060137051039626487), np.float64(0.06545368620030073), np.float64(0.15311909262741832), np.float64(0.23275047258951706), np.float64(0.1668241965971564), np.float64(0.09416351606794167), np.float64(0.057774102079326824), np.float64(0.053520793950787425), np.float64(0.08601134215490783), np.float64(0.0), np.float64(0.03898865784494448), np.float64(0.07466918714546943), np.float64(0.05552930056704214), np.float64(0.13019848771251158), np.float64(0.23192344045341218), np.float64(0.15524574669168803), np.float64(0.08459357277872802), np.float64(0.06887996219273525), np.float64(0.06344517958404602), np.float64(0.09652646502824133), np.float64(0.0), np.float64(0.0417060491492891), np.float64(0.07242438563318475), np.float64(0.05730151228726689), np.float64(0.1307892249525865), np.float64(0.23475897920577177), np.float64(0.14520321361041444), np.float64(0.0784499054819489), np.float64(0.07301512287325966), np.float64(0.06628071833640561), np.float64(0.10007088846869083), np.float64(0.0), np.float64(0.037570888468764684), np.float64(0.0699432892248701), np.float64(0.0678166351606004), np.float64(0.13622400756127573), np.float64(0.19884215500921684), np.float64(0.14792060491475906), np.float64(0.10148865784487063), np.float64(0.07478733459348441), np.float64(0.0656899810963307), np.float64(0.09971644612464588), np.float64(0.0), np.float64(0.03591682419655492), np.float64(0.07077032136097498), np.float64(0.06734404536854047), np.float64(0.13882325141760535), np.float64(0.19340737240052763), np.float64(0.14402173913026461), np.float64(0.09829867674846608), np.float64(0.07396030245737953), np.float64(0.07029773156891504), np.float64(0.10715973534958984), np.float64(0.0), np.float64(0.02528355387520642), np.float64(0.06545368620030073), np.float64(0.056828922495206956), np.float64(0.1398865784497402), np.float64(0.19978733459333672), np.float64(0.18064744801490942), np.float64(0.10491493383730514), np.float64(0.06899810964075023), np.float64(0.07006143667288509), np.float64(0.08813799621917752), np.float64(0.0), np.float64(0.027528355387491103), np.float64(0.055293005671012176), np.float64(0.05422967863887732), np.float64(0.1609168241964072), np.float64(0.2125472589789549), np.float64(0.18206521739108922), np.float64(0.10267013232502047), np.float64(0.06190926275985124), np.float64(0.06332703213603104), np.float64(0.07951323251408374), np.float64(0.0), np.float64(0.0374527410207497), np.float64(0.0699432892248701), np.float64(0.0692344045367802), np.float64(0.1524102079393284), np.float64(0.18560964083153872), np.float64(0.14709357277865417), np.float64(0.10633270321348495), np.float64(0.0671077504725105), np.float64(0.06403591682412094), np.float64(0.10077977315678073), np.float64(0.0), np.float64(0.036625708884644816), np.float64(0.06687145557648053), np.float64(0.0663988657844206), np.float64(0.14413988657827959), np.float64(0.19317107750449766), np.float64(0.1512287334591786), np.float64(0.10160680529288561), np.float64(0.06899810964075023), np.float64(0.07065217391296), np.float64(0.1003071833647208), np.float64(0.0), np.float64(0.028000945179551037), np.float64(0.07100661625700495), np.float64(0.04076086956516923), np.float64(0.12405482041573243), np.float64(0.346172022683901), np.float64(0.1427221172020998), np.float64(0.06261814744794114), np.float64(0.0685255198486903), np.float64(0.04690453686194836), np.float64(0.0692344045367802), np.float64(0.0), np.float64(0.04288752362943893), np.float64(0.08459357277872802), np.float64(0.06604442344037564), np.float64(0.12665406427206208), np.float64(0.2126654064269699), np.float64(0.12771739130419693), np.float64(0.08364839319460816), np.float64(0.07974952741011371), np.float64(0.06793478260861538), np.float64(0.10810491493370969), np.float64(0.0), np.float64(0.042414933837378994), np.float64(0.07384215500936454), np.float64(0.06533553875228575), np.float64(0.1392958412096653), np.float64(0.16209829867655706), np.float64(0.14851134215483397), np.float64(0.09723534971633123), np.float64(0.07904064272202381), np.float64(0.07939508506606877), np.float64(0.11283081285430903), np.float64(0.0), np.float64(0.04324196597348388), np.float64(0.07230623818516976), np.float64(0.06675330812846555), np.float64(0.13657844990532067), np.float64(0.1668241965971564), np.float64(0.14673913043460923), np.float64(0.10196124763693057), np.float64(0.07679584120973913), np.float64(0.0762051039696642), np.float64(0.11259451795827906), np.float64(0.0), np.float64(0.03379017013228522), np.float64(0.060845935727716384), np.float64(0.06179111531183625), np.float64(0.14969281663498382), np.float64(0.22188090737213859), np.float64(0.1573724007559577), np.float64(0.09085538752352214), np.float64(0.06828922495266034), np.float64(0.06368147448007598), np.float64(0.091800567107642), np.float64(0.0), np.float64(0.02776465028352107), np.float64(0.058364839319401736), np.float64(0.05623818525513204), np.float64(0.15489130434764306), np.float64(0.24350189035888054), np.float64(0.16268903591663197), np.float64(0.09428166351595665), np.float64(0.06521739130427076), np.float64(0.05612003780711706), np.float64(0.08093100189026355), np.float64(0.0), np.float64(0.042651228733408965), np.float64(0.07644139886569418), np.float64(0.0649810964082408), np.float64(0.1468572778826242), np.float64(0.16339792060472186), np.float64(0.14083175803386005), np.float64(0.10574196597341003), np.float64(0.0804584120982036), np.float64(0.07017958412090007), np.float64(0.10845935727775464), np.float64(0.0), np.float64(0.038752362948914515), np.float64(0.07514177693752937), np.float64(0.06415406427213592), np.float64(0.13551512287318582), np.float64(0.18809073723985337), np.float64(0.1525283553873434), np.float64(0.09428166351595665), np.float64(0.07715028355378407), np.float64(0.06840737240067532), np.float64(0.10597826086944), np.float64(0.0), np.float64(0.025756143667266352), np.float64(0.06060964083168642), np.float64(0.044187145557603745), np.float64(0.12665406427206208), np.float64(0.3015122873342373), np.float64(0.17202268430981565), np.float64(0.08104914933827853), np.float64(0.06190926275985124), np.float64(0.05186672967857766), np.float64(0.07443289224943946), np.float64(0.0), np.float64(0.040642722117154244), np.float64(0.07100661625700495), np.float64(0.058601134215431706), np.float64(0.12110113421535786), np.float64(0.2733931947066713), np.float64(0.1428402646501148), np.float64(0.07017958412090007), np.float64(0.07195179584112481), np.float64(0.05978260869558154), np.float64(0.09050094517947718), np.float64(0.0), np.float64(0.05068525519842782), np.float64(0.08305765595453324), np.float64(0.06982514177685512), np.float64(0.12665406427206208), np.float64(0.15961720226824241), np.float64(0.1333884688089161), np.float64(0.09475425330801658), np.float64(0.084711720226743), np.float64(0.07644139886569418), np.float64(0.12086483931932789), np.float64(0.0), np.float64(0.04525047258973859), np.float64(0.07254253308119973), np.float64(0.07608695652164923), np.float64(0.14496691871438447), np.float64(0.17521266540622019), np.float64(0.1320888468807513), np.float64(0.09487240075603157), np.float64(0.07904064272202381), np.float64(0.06935255198479519), np.float64(0.11058601134202435), np.float64(0.0), np.float64(0.029773156899775784), np.float64(0.05068525519842782), np.float64(0.056828922495206956), np.float64(0.15961720226824241), np.float64(0.26973062381820684), np.float64(0.14780245746674409), np.float64(0.0811672967862935), np.float64(0.06379962192809097), np.float64(0.05753780718329685), np.float64(0.08305765595453324), np.float64(0.0), np.float64(0.03166351606801552), np.float64(0.05801039697535679), np.float64(0.05399338374284736), np.float64(0.16008979206030233), np.float64(0.25248109640801925), np.float64(0.14520321361041444), np.float64(0.08683837429101271), np.float64(0.06758034026457044), np.float64(0.05978260869558154), np.float64(0.08435727788269806), np.float64(0.0), np.float64(0.05033081285438287), np.float64(0.07809546313790394), np.float64(0.07065217391296), np.float64(0.14142249527393497), np.float64(0.1505198487710887), np.float64(0.1356332703212008), np.float64(0.09995274102067585), np.float64(0.0784499054819489), np.float64(0.0734877126653196), np.float64(0.12145557655940281), np.float64(0.0), np.float64(0.038516068052884544), np.float64(0.07254253308119973), np.float64(0.0621455576558812), np.float64(0.12417296786374742), np.float64(0.26394139886547263), np.float64(0.1327977315688412), np.float64(0.07336956521730462), np.float64(0.07266068052921472), np.float64(0.0628544423439711), np.float64(0.09699905482030127), np.float64(0.0), np.float64(0.02055765595460709), np.float64(0.054465973534907286), np.float64(0.03969754253303438), np.float64(0.12169187145543277), np.float64(0.21975425330786888), np.float64(0.2019139886576064), np.float64(0.09310018903580682), np.float64(0.062263705103896186), np.float64(0.10645085066149992), np.float64(0.08010396975415866), np.float64(0.0), np.float64(0.03473534971640508), np.float64(0.06958884688082514), np.float64(0.05706521739123692), np.float64(0.1363421550092907), np.float64(0.2606332703210531), np.float64(0.1560727788277929), np.float64(0.08211247637041337), np.float64(0.06521739130427076), np.float64(0.05517485822299719), np.float64(0.08305765595453324), np.float64(0.0), np.float64(0.04336011342149886), np.float64(0.07585066162561926), np.float64(0.06793478260861538), np.float64(0.13905954631363532), np.float64(0.1843100189033739), np.float64(0.14732986767468415), np.float64(0.09487240075603157), np.float64(0.07171550094509485), np.float64(0.07065217391296), np.float64(0.10491493383730514), np.float64(0.0), np.float64(0.060137051039626487), np.float64(0.09380907372389671), np.float64(0.07585066162561926), np.float64(0.12169187145543277), np.float64(0.13043478260854152), np.float64(0.11318525519835397), np.float64(0.09215500945168695), np.float64(0.09451795841198662), np.float64(0.08282136105850328), np.float64(0.13539697542517085), np.float64(0.0), np.float64(0.052339319470637594), np.float64(0.07667769376172415), np.float64(0.07112476370501992), np.float64(0.14106805292989003), np.float64(0.14532136105842944), np.float64(0.1313799621926614), np.float64(0.0981805293004511), np.float64(0.08329395085056321), np.float64(0.07703213610576909), np.float64(0.1235822306236725), np.float64(0.0), np.float64(0.04584120982981351), np.float64(0.07809546313790394), np.float64(0.07360586011333457), np.float64(0.14366729678621967), np.float64(0.15288279773138835), np.float64(0.13267958412082623), np.float64(0.10479678638929016), np.float64(0.07762287334584402), np.float64(0.07738657844981404), np.float64(0.11342155009438394), np.float64(0.0), np.float64(0.06297258979198608), np.float64(0.08388468809063812), np.float64(0.07407844990539451), np.float64(0.12299149338359759), np.float64(0.1476843100187291), np.float64(0.1164933837427735), np.float64(0.08104914933827853), np.float64(0.08754725897910261), np.float64(0.08624763705093778), np.float64(0.1370510396973806), np.float64(0.0), np.float64(0.02953686200374582), np.float64(0.057774102079326824), np.float64(0.05741965973528187), np.float64(0.1370510396973806), np.float64(0.27528355387491105), np.float64(0.1745037807181303), np.float64(0.07750472589782903), np.float64(0.058955576559476655), np.float64(0.05056710775041284), np.float64(0.08140359168232347), np.float64(0.0), np.float64(0.023629489602996656), np.float64(0.048440453686143144), np.float64(0.040524574669139266), np.float64(0.12547258979191223), np.float64(0.21148393194682005), np.float64(0.19529773156876734), np.float64(0.08943761814734234), np.float64(0.07195179584112481), np.float64(0.12334593572764253), np.float64(0.07041587901693003), np.float64(0.0)]\n",
      "(741, 741)\n"
     ]
    }
   ],
   "source": [
    "#read image\n",
    "image_path = \"data/112.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "#convert the image to gray scale\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "bounding_box = detect_faces(image_path, 1.2, 3, (20, 20))\n",
    "\n",
    "grid_size = (8, 8)\n",
    "n_points = 8\n",
    "radius = 1\n",
    "method = \"uniform\"\n",
    "\n",
    "face_region = image[bounding_box[1] : bounding_box[1] + bounding_box[3],\n",
    "    bounding_box[0] : bounding_box[0] + bounding_box[2]]\n",
    "if bounding_box.all():\n",
    "    lbp = local_binary_pattern(face_region, n_points, radius, method=method)\n",
    "else:\n",
    "    lbp = 255*np.ones((face_region.shape[0], face_region.shape[1]))\n",
    "\n",
    "features = []\n",
    "\n",
    "# Divide the image into grids\n",
    "h, w = lbp.shape\n",
    "grid_h, grid_w = h // grid_size[0], w // grid_size[1]\n",
    "print(grid_h, grid_w)\n",
    "\n",
    "for i in range(grid_size[0]):  # Rows\n",
    "    for j in range(grid_size[1]):  # Columns\n",
    "        # Extract grid region\n",
    "        grid = lbp[i * grid_h:(i + 1) * grid_h, j * grid_w:(j + 1) * grid_w]\n",
    "        \n",
    "        # Compute histogram\n",
    "        hist, _ = np.histogram(grid.ravel(), bins=n_points+3, range=(0, n_points + 2))\n",
    "        \n",
    "\n",
    "        # Normalize histogram\n",
    "        hist = hist / (np.sum(hist) + 1e-8)\n",
    "        \n",
    "        \n",
    "        # Append to feature vector\n",
    "        features.extend(hist)\n",
    "\n",
    "print(np.array(features).shape)\n",
    "print(features)\n",
    "print(lbp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, n_points + 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "0.7108736390202173\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Load the image \n",
    "image_path = \"data/112.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "\n",
    "HEIGHT = image.shape[0]\n",
    "WIDTH = image.shape[1]\n",
    "\n",
    "faces = detect_faces(image_path, 1.2, 6, (40, 40))\n",
    "print(faces.shape)\n",
    "\n",
    "box_annot = df.loc[df['idx'] == int(image_path.split('/')[-1].split('.')[0]), ['x_1', 'y_1', 'width', 'height']].values\n",
    "box_annot = box_annot.flatten()\n",
    "\n",
    "\n",
    "print(compute_iou(faces, box_annot))\n",
    "\n",
    "cv2.rectangle(image, (faces[0], faces[1]), (faces[0]+faces[2], faces[1]+faces[3]), (255, 0, 0), 2)\n",
    "cv2.rectangle(image, (box_annot[0], box_annot[1]), (box_annot[0]+box_annot[2], box_annot[1]+box_annot[3]), (0, 255, 255), 2)\n",
    "\n",
    "# Display the image\n",
    "cv2.namedWindow(\"Detected Faces\", cv2.WINDOW_NORMAL) \n",
    "cv2.resizeWindow(\"Detected Faces\", int(WIDTH*0.8), int(0.8*HEIGHT))\n",
    "cv2.imshow(\"Detected Faces\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibb_face_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
